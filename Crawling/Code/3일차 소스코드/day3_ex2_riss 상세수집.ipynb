{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색하신 키워드 빅데이터 (으)로 총 5,870 건의 학위논문이 검색되었습니다\n",
      "15 건의 데이터를 수집하기 위해 2 페이지의 게시물을 조회합니다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1 페이지 내용 수집 시작합니다 =======================\n",
      "\n",
      "\n",
      "1 번째 정보를 추출하고 있습니다============\n",
      "1.번호 : 1\n",
      "2.제목 : 조직, 개인 그리고 경영품질 관점에서 기업의 빅데이터 활용의도에 영향을 미치는 핵심요인에 관한 연구\n",
      "3.작성자 : 신수행\n",
      "4.소속기관 : 전남대학교\n",
      "5.발표년도 : 2019\n",
      "6.학위여부 : 국내박사\n",
      "7.초록내용 : Recently the term '4th industrial revolution' was mentioned in the World Economic Forum (WEF). Since then, it has become a representative of the new 'next-generation industrial revolution' based on information and communication technology (ICT) and is...\n",
      "8.논문 URL 주소: http://www.riss.kr/search/detail/DetailView.do?p_mat_type=be54d9b8bc7cdb09&control_no=30bd6c9883e852acffe0bdc3ef48d419&keyword=빅데이터\n",
      "\n",
      "\n",
      "2 번째 정보를 추출하고 있습니다============\n",
      "1.번호 : 2\n",
      "2.제목 : 빅데이터 처리 프로세스의 위험요인에 관한 연구\n",
      "3.작성자 : 이지은\n",
      "4.소속기관 : 숭실대학교 소프트웨어특성화대학원\n",
      "5.발표년도 : 2015\n",
      "6.학위여부 : 국내석사\n",
      "7.초록내용 : 최근 빅데이터 도입으로 긍정적인 결과를 얻음으로써 빅데이터 활용 가치가 높이 평가되고 있다. 따라서 빅데이터를 활용하여 이윤을 창출하고자 하는 기업 및 기관이 점차 증가하고 있다. ...\n",
      "8.논문 URL 주소: http://www.riss.kr/search/detail/DetailView.do?p_mat_type=be54d9b8bc7cdb09&control_no=1ee950ad6a468bcbffe0bdc3ef48d419&keyword=빅데이터\n",
      "\n",
      "\n",
      "3 번째 정보를 추출하고 있습니다============\n",
      "1.번호 : 3\n",
      "2.제목 : 공간 빅데이터 플랫폼의 실증 및 지하자료에 대한 적용\n",
      "3.작성자 : 권일룡\n",
      "4.소속기관 : 충북대학교\n",
      "5.발표년도 : 2021\n",
      "6.학위여부 : 국내박사\n",
      "7.초록내용 : 4차산업 혁명으로 인해 데이터의 수집, 분석, 처리가 고도화 되고 이로 인해 빅데이터의 중요성도 점점 커지고 있다. 판교는 국내유일의 실제 도로기반 자율주행 시범운행지구로서 자율주행...\n",
      "8.논문 URL 주소: http://www.riss.kr/search/detail/DetailView.do?p_mat_type=be54d9b8bc7cdb09&control_no=99e25ae9859cf3efffe0bdc3ef48d419&keyword=빅데이터\n",
      "\n",
      "\n",
      "4 번째 정보를 추출하고 있습니다============\n",
      "1.번호 : 4\n",
      "2.제목 : 빅데이터와 카노모델 비교분석을 통한 배달앱 선택속성이 소비자만족 사용의도에 미치는 영향\n",
      "3.작성자 : 임정숙\n",
      "4.소속기관 : 광운대학교 일반대학원\n",
      "5.발표년도 : 2022\n",
      "6.학위여부 : 국내박사\n",
      "7.초록내용 : 본 논문은 외식업체의 배달앱 선택속성이 소비자 만족과 사용의도에 미치는 영향을 알아보기 위해 선행연구를 바탕으로 배달앱의 선택속성을 편의성, 다양성, 정보성 3가지 요인으로 설정...\n",
      "8.논문 URL 주소: http://www.riss.kr/search/detail/DetailView.do?p_mat_type=be54d9b8bc7cdb09&control_no=c3424b950a91c29fffe0bdc3ef48d419&keyword=빅데이터\n",
      "\n",
      "\n",
      "5 번째 정보를 추출하고 있습니다============\n",
      "1.번호 : 5\n",
      "2.제목 : 빅데이터 환경에서 개인정보 이용에 관한 법적 고찰\n",
      "3.작성자 : 정원준\n",
      "4.소속기관 : 고려대학교 대학원\n",
      "5.발표년도 : 2019\n",
      "6.학위여부 : 국내박사\n",
      "7.초록내용 : 빅데이터는 미래 예측분석, 사회적 난제 해결, 신산업 발전 도모 등을 좌우할 수 있을 만큼 큰 파급력을 가진다. 빅데이터 활용을 통해 특정 패턴이나 링크, 행동, 트렌드, 정체성, 실용 지식 ...\n",
      "8.논문 URL 주소: http://www.riss.kr/search/detail/DetailView.do?p_mat_type=be54d9b8bc7cdb09&control_no=dac2f2dbde5b63dfffe0bdc3ef48d419&keyword=빅데이터\n",
      "\n",
      "\n",
      "6 번째 정보를 추출하고 있습니다============\n",
      "1.번호 : 6\n",
      "2.제목 : 빅데이터를 처리할 수 있는 인공지능 모델 기반의 상황인지 시스템\n",
      "3.작성자 : 조용성\n",
      "4.소속기관 : 숭실대학교 대학원\n",
      "5.발표년도 : 2018\n",
      "6.학위여부 : 국내박사\n",
      "7.초록내용 : 최근 지능형 로봇 서비스를 제공하기 위해서 사물인터넷과 로봇 HRI 모듈에서 수집된 빅데이터를 지능형 로봇의 상황인지에 적용하려는 연구가 진행되고 있다. 수집된 빅데이터는 정형 데이...\n",
      "8.논문 URL 주소: http://www.riss.kr/search/detail/DetailView.do?p_mat_type=be54d9b8bc7cdb09&control_no=80cf63b5c3f47a3affe0bdc3ef48d419&keyword=빅데이터\n",
      "\n",
      "\n",
      "7 번째 정보를 추출하고 있습니다============\n",
      "1.번호 : 7\n",
      "2.제목 : 빅데이터를 활용한 마케팅 전략 실행의 실제에 관한 연구\n",
      "3.작성자 : 송민석\n",
      "4.소속기관 : 한국교통대학교 일반대학원\n",
      "5.발표년도 : 2014\n",
      "6.학위여부 : 국내석사\n",
      "7.초록내용 : 본 연구는 빅데이터를 활용한 마케팅 전략 실행의 실제에 관한 연구이다.  정보화시대를 맞이하여 최근 세계경제는 디지털 시대에 맞는 경제발전에 관심을 보이고 있으며, 많은 양의 정...\n",
      "8.논문 URL 주소: http://www.riss.kr/search/detail/DetailView.do?p_mat_type=be54d9b8bc7cdb09&control_no=2813dfbe704f8b64ffe0bdc3ef48d419&keyword=빅데이터\n",
      "\n",
      "\n",
      "8 번째 정보를 추출하고 있습니다============\n",
      "1.번호 : 8\n",
      "2.제목 : 기업의 빅데이터 활용 유형별 적용 방안 및 효과 분석\n",
      "3.작성자 : 이재성\n",
      "4.소속기관 : 한신대학교 대학원\n",
      "5.발표년도 : 2014\n",
      "6.학위여부 : 국내박사\n",
      "7.초록내용 : 지난 수년 간 스마트폰과 같은 스마트 기기의 빠른 확산과 함께 인터넷과 소셜네트워크서비스(SNS, Social network Service) 등 소셜 미디어가 급성장함에 따라 개인정보와 소비패턴, 위치정보 등이...\n",
      "8.논문 URL 주소: http://www.riss.kr/search/detail/DetailView.do?p_mat_type=be54d9b8bc7cdb09&control_no=63b4ffcefd45c47fffe0bdc3ef48d419&keyword=빅데이터\n",
      "\n",
      "\n",
      "9 번째 정보를 추출하고 있습니다============\n",
      "1.번호 : 9\n",
      "2.제목 : 다차원 분석기법을 통한 빅데이터 분야 특허 가치 평가\n",
      "3.작성자 : 노승윤\n",
      "4.소속기관 : 충북대학교\n",
      "5.발표년도 : 2014\n",
      "6.학위여부 : 국내석사\n",
      "7.초록내용 : 2010년대에 들어와 정보통신기술(ICT, Information and Communications Technology) 산업의 빅데이터 비즈니스에 대한 관심이 점차 높아지고 있으며, 세계주요 국가들도 빅데이터를 2012년 이후의 ICT 산업을...\n",
      "8.논문 URL 주소: http://www.riss.kr/search/detail/DetailView.do?p_mat_type=be54d9b8bc7cdb09&control_no=17bd6ec026a0523fffe0bdc3ef48d419&keyword=빅데이터\n",
      "\n",
      "\n",
      "10 번째 정보를 추출하고 있습니다============\n",
      "1.번호 : 10\n",
      "2.제목 : 디지털 리터러시 기반의 빅데이터 시각화 소프트웨어의 유지보수 모델\n",
      "3.작성자 : 한충구\n",
      "4.소속기관 : 숭실대학교 정보과학대학원\n",
      "5.발표년도 : 2020\n",
      "6.학위여부 : 국내석사\n",
      "7.초록내용 : 빅데이터 처리 기술은 4 차 산업혁명의 시대를 선도하는 다양한 혁신 기술들 중 하나이다. 빅데이터 처리 기술은 수집, 저장, 분석, 시각화 등 다양한 관점에서 세부 기술 집합으로 구분하여 ...\n",
      "8.논문 URL 주소: http://www.riss.kr/search/detail/DetailView.do?p_mat_type=be54d9b8bc7cdb09&control_no=880c23b98fd3c975ffe0bdc3ef48d419&keyword=빅데이터\n",
      "\n",
      "\n",
      "2 페이지 내용 수집 시작합니다 =======================\n",
      "\n",
      "\n",
      "11 번째 정보를 추출하고 있습니다============\n",
      "1.번호 : 11\n",
      "2.제목 : DACUM 기법을 활용한 빅데이터 직무능력모형 개발\n",
      "3.작성자 : 송현민\n",
      "4.소속기관 : 고려대학교 교육대학원\n",
      "5.발표년도 : 2015\n",
      "6.학위여부 : 국내석사\n",
      "7.초록내용 : 본 논문의 목적은 현업에서 요구하는 체계화된 빅데이터 직무별 교육 프로그램 개발을 위해, 직무 및 역량에 대한 분석을 토대로 빅데이터 직무능력모형을 개발하는 것이었다.이를 위해 ...\n",
      "8.논문 URL 주소: http://www.riss.kr/search/detail/DetailView.do?p_mat_type=be54d9b8bc7cdb09&control_no=b1310ea6e0eb8019ffe0bdc3ef48d419&keyword=빅데이터\n",
      "\n",
      "\n",
      "12 번째 정보를 추출하고 있습니다============\n",
      "1.번호 : 12\n",
      "2.제목 : 빅데이터 시대의 개인정보 제공에 영향을 미치는 프라이버시 요인 연구\n",
      "3.작성자 : 민현홍\n",
      "4.소속기관 : 숭실대학교\n",
      "5.발표년도 : 2016\n",
      "6.학위여부 : 국내석사\n",
      "7.초록내용 : Recently, the appearance of Big Data has been drawing great attention from managerial scholars and journals worldwide such as Harvard Business Review, New York Times, etc. It is also considered as the most attractive industry in the 21st century. The ...\n",
      "8.논문 URL 주소: http://www.riss.kr/search/detail/DetailView.do?p_mat_type=be54d9b8bc7cdb09&control_no=ffdf238fd2e4cbd9ffe0bdc3ef48d419&keyword=빅데이터\n",
      "\n",
      "\n",
      "13 번째 정보를 추출하고 있습니다============\n",
      "1.번호 : 13\n",
      "2.제목 : 토픽모델링을 이용한 빅데이터 동향의 다각적 분석\n",
      "3.작성자 : 민혜종\n",
      "4.소속기관 : 서울과학기술대학교\n",
      "5.발표년도 : 2015\n",
      "6.학위여부 : 국내석사\n",
      "7.초록내용 : 최근 빅데이터에 대한 관심이 기업 및 학계에서 두드러지고 있다. 빅데이터는 다양한 분야 및 영역에서 광범위하게 사용되고 있는 용어로서 이에 대한 동향을 파악하기 위해서는 빅데이터...\n",
      "8.논문 URL 주소: http://www.riss.kr/search/detail/DetailView.do?p_mat_type=be54d9b8bc7cdb09&control_no=66888fbbe433eea0ffe0bdc3ef48d419&keyword=빅데이터\n",
      "\n",
      "\n",
      "14 번째 정보를 추출하고 있습니다============\n",
      "1.번호 : 14\n",
      "2.제목 : 빅데이터 기반의 자금세탁방지 시스템 연구\n",
      "3.작성자 : 김상완\n",
      "4.소속기관 : 건국대학교 정보통신대학원\n",
      "5.발표년도 : 2014\n",
      "6.학위여부 : 국내석사\n",
      "7.초록내용 : 빅데이터 시대가 도래 하면서 오늘날 기업은 단순히 많은 데이터를 보유하는 것은 의미가 없어지고 데이터가 조직의 목표에 부합하여 기업의 경쟁력을 높일 수 있도록 정보 시스템의 통합...\n",
      "8.논문 URL 주소: http://www.riss.kr/search/detail/DetailView.do?p_mat_type=be54d9b8bc7cdb09&control_no=34c93ccbd0c78bb9ffe0bdc3ef48d419&keyword=빅데이터\n",
      "\n",
      "\n",
      "15 번째 정보를 추출하고 있습니다============\n",
      "1.번호 : 15\n",
      "2.제목 : 빅데이터 기술에 기반한 그린IT 분류체계 수립 및 그린IT 활성화를 위한 전략적 과제 연구 : 비즈니스 활성화와 정책수립 관점\n",
      "3.작성자 : 백현\n",
      "4.소속기관 : 한양사이버대학교 경영대학원\n",
      "5.발표년도 : 2014\n",
      "6.학위여부 : 국내석사\n",
      "7.초록내용 : Recently, the information technology (IT) is significantly developed and plays an important role in many areas. When IT is applied to solve energy and environmental issues and to help the sustainable development of human beings, it is called as “Gre...\n",
      "8.논문 URL 주소: http://www.riss.kr/search/detail/DetailView.do?p_mat_type=be54d9b8bc7cdb09&control_no=ac281df2a7a49305ffe0bdc3ef48d419&keyword=빅데이터\n",
      "요청하신 작업이 모두 완료되었습니다\n",
      "요청하신 데이터 수집 작업이 정상적으로 완료되었습니다\n"
     ]
    }
   ],
   "source": [
    "# Chap 15.riss.kr 에서 특정 키워드로 논문 / 학술 자료 검색하기\n",
    "\n",
    "#Step 1. 필요한 모듈을 로딩합니다\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "import time \n",
    "\n",
    "#Step 2. 사용자에게 검색 관련 정보들을 입력 받습니다.\n",
    "query_txt = '빅데이터'\n",
    "\n",
    "#Step 3. 수집된 데이터를 저장할 파일 이름 입력받기 \n",
    "f_dir = input(\"2.파일을 저장할 폴더명만 쓰세요(기본값:c:\\\\py_temp\\\\):\")\n",
    "if f_dir == '' :\n",
    "    f_dir=\"c:\\\\py_temp\\\\\"\n",
    "\n",
    "#Step 4. 크롬 드라이버 설정 및 웹 페이지 열기\n",
    "driver = webdriver.Chrome()\n",
    "url = 'http://www.riss.kr/'\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "\n",
    "main = driver.window_handles\n",
    "for handle in main:\n",
    "    if handle != main[0]:\n",
    "        driver.switch_to.window(handle)\n",
    "        driver.close()\n",
    "\n",
    "driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "#Step 5. 자동으로 검색어 입력 후 조회하기\n",
    "driver.find_element(By.ID,'query').send_keys(query_txt+'\\n')\n",
    "\n",
    "#Step 6.학위 논문 선택하기\n",
    "driver.find_element(By.LINK_TEXT,'학위논문').click()\n",
    "time.sleep(2)\n",
    "\n",
    "#Step 7.Beautiful Soup 로 본문 내용만 추출하기\n",
    "from bs4 import BeautifulSoup\n",
    "soup_1 = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "#Step 8. 총 검색 건수를 보여주고 수집할 건수 입력받기\n",
    "import math\n",
    "total_cnt = soup_1.find('div','searchBox pd').find('span','num').get_text()\n",
    "print('검색하신 키워드 %s (으)로 총 %s 건의 학위논문이 검색되었습니다' %(query_txt,total_cnt))\n",
    "cnt = 15\n",
    "page_cnt = math.ceil(cnt / 10)\n",
    "print('%s 건의 데이터를 수집하기 위해 %s 페이지의 게시물을 조회합니다.' %(cnt,page_cnt))\n",
    "print(\"\\n\")\n",
    "\n",
    "#Step 9. 데이터 수집하기\n",
    "no2=[]           # 게시글 번호 컬럼\n",
    "title2=[ ]       # 게시글 제목 컬럼\n",
    "author2=[]       # 논문 저자 컬럼\n",
    "company2=[ ]     # 소속 기관 컬럼\n",
    "date2=[ ]        # 게시글 날짜 컬럼\n",
    "suksa2=[ ]       # 국내석사 컬럼\n",
    "contents2=[]     # 초록내용\n",
    "full_url2=[]     # 논문 원본 URL\n",
    "\n",
    "no = 1           # 게시글 번호 초기값\n",
    "            \n",
    "for a in range(1,page_cnt+1) :\n",
    "    print(\"\\n\")\n",
    "    print(\"%s 페이지 내용 수집 시작합니다 =======================\" %a)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    content_list = soup.find('div','srchResultListW').find_all('li')\n",
    "\n",
    "    for i in content_list:\n",
    "        # 논문 제목 체크하기\n",
    "        try:\n",
    "            title=i.find('p','title').get_text().strip()\n",
    "        except :\n",
    "            continue \n",
    "        else :\n",
    "            # 1.게시글 번호\n",
    "            print(\"\\n\")\n",
    "            print(\"%s 번째 정보를 추출하고 있습니다============\" %no)\n",
    "            no2.append(no)\n",
    "            print(\"1.번호 : %s\" %no)\n",
    "            \n",
    "            # 2. 논문 제목\n",
    "            title2.append(title.strip())\n",
    "            print(\"2.제목 : %s\" %title.strip())\n",
    "\n",
    "            # 3. 작성자\n",
    "            try :\n",
    "                author=i.find('p','etc').find('span','writer').get_text().strip()\n",
    "            except :\n",
    "                author = '작성자가 없습니다'\n",
    "                print(\"3.작성자 : %s\" %author.strip())\n",
    "                author2.append(author.strip())\n",
    "            else :\n",
    "                author2.append(author.strip())\n",
    "                print(\"3.작성자 : %s\" %author.strip())\n",
    "\n",
    "            # 4. 소속기관\n",
    "            try :\n",
    "                company=i.find('p','etc').find('span','assigned').get_text().strip()\n",
    "            except :\n",
    "                company='소속 기관이 없습니다'\n",
    "                company2.append(company.strip())\n",
    "                print(\"4.소속기관 : %s\" %company.strip())\n",
    "            else :\n",
    "                company2.append(company.strip())\n",
    "                print(\"4.소속기관 : %s\" %company.strip())\n",
    "\n",
    "            # 5. 발표날짜\n",
    "            try :\n",
    "                date_1 =i.find('p','etc').find_all('span')\n",
    "                date_2 = date_1[2].get_text().strip()\n",
    "            except :\n",
    "                date_2='발표날짜가 없습니다'\n",
    "                date2.append(date_2)\n",
    "                print(\"5.발표년도 : %s\" %date_2)\n",
    "            else :\n",
    "                date2.append(date_2)\n",
    "                print(\"5.발표년도 : %s\" %date_2)\n",
    "\n",
    "            # 6.학위여부\n",
    "            try :\n",
    "                suksa_1 =i.find('p','etc').find_all('span')\n",
    "                suksa_2 = suksa_1[3].get_text().strip()\n",
    "            except :\n",
    "                suksa_2='학위가 없습니다'\n",
    "                suksa2.append(suksa_2)\n",
    "                print(\"6.학위여부 : %s\" %suksa_2)\n",
    "            else :\n",
    "                suksa2.append(suksa_2)\n",
    "                print(\"6.학위여부 : %s\" %suksa_2)\n",
    "\n",
    "            # 7.초록 내용-해당 논문의 상세 내역에서 추출할 수 있음.    \n",
    "            url_1 = i.find('p','title').find('a')['href']\n",
    "            full_url = 'http://www.riss.kr'+url_1\n",
    "            time.sleep(1)\n",
    "            driver.get(full_url)\n",
    "\n",
    "            soup_1 = BeautifulSoup(driver.page_source, 'html.parser')  \n",
    "            try :\n",
    "                cont=soup_1.find(\"div\",\"text\").find('p').get_text().replace(\"\\n\",\"\").strip()\n",
    "            except :\n",
    "                cont='초록이 없습니다'\n",
    "                contents2.append(cont)\n",
    "                print(\"7.초록내용 : %s\" %cont)\n",
    "            else :\n",
    "                contents2.append(cont)\n",
    "                print(\"7.초록내용 : %s\" %cont)\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "            # 8.논문 url 주소\n",
    "            full_url2.append(full_url)\n",
    "            print('8.논문 URL 주소:' , full_url)\n",
    "\n",
    "            driver.back()  # 이전 페이지로 돌아가기\n",
    "\n",
    "            time.sleep(2)\n",
    "\n",
    "            no += 1\n",
    "            \n",
    "            if no > cnt :\n",
    "                break \n",
    "                            \n",
    "    a += 1 \n",
    "    b = str(a)\n",
    "\n",
    "    try :\n",
    "        driver.find_element(By.LINK_TEXT ,'%s' %b).click() \n",
    "    except :\n",
    "        driver.find_element(By.LINK_TEXT,'다음 페이지로').click()\n",
    "        \n",
    "print(\"요청하신 작업이 모두 완료되었습니다\")\n",
    "\n",
    "# Step 10. 수집된 데이터를 xls와 csv 형태로 저장하기\n",
    "# 현재 날짜와 시간으로 폴더 만들고 파일 이름 설정하기\n",
    "import os\n",
    "\n",
    "n = time.localtime()\n",
    "s = '%04d-%02d-%02d-%02d-%02d-%02d' %(n.tm_year, n.tm_mon, n.tm_mday, n.tm_hour, n.tm_min, n.tm_sec)\n",
    "\n",
    "os.makedirs(f_dir+'RISS'+'-'+s+'-'+'학위논문')\n",
    "\n",
    "fc_name = f_dir+'RISS'+'-'+s+'-'+'학위논문'+'\\\\'+'RISS'+'-'+s+'-'+'학위논문'+'.csv'\n",
    "fx_name = f_dir+'RISS'+'-'+s+'-'+'학위논문'+'\\\\'+'RISS'+'-'+s+'-'+'학위논문'+'.xls'\n",
    "\n",
    "# 데이터 프레임 생성 후 xls , csv 형식으로 저장하기\n",
    "import pandas as pd \n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['번호']=no2\n",
    "df['제목']=pd.Series(title2)\n",
    "df['저자']=pd.Series(author2)\n",
    "df['소속(발행)기관']=pd.Series(company2)\n",
    "df['날짜']=pd.Series(date2)\n",
    "df['학위(논문일경우)']=pd.Series(suksa2)\n",
    "df['초록(논문일경우)']=pd.Series(contents2)\n",
    "df['자료URL주소']=pd.Series(full_url2)\n",
    "\n",
    "# xls 형태로 저장하기\n",
    "df.to_excel(fx_name, index=False, engine='openpyxl')\n",
    "\n",
    "# csv 형태로 저장하기\n",
    "df.to_csv(fc_name, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print('요청하신 데이터 수집 작업이 정상적으로 완료되었습니다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "8965150514684192fd1d81b86341baebb0ab118aa72b57568cb073ce4741e3b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
